---
title: "教程4: 读取10X MTX格式数据并转换为H5AD"
author: "ICellbioRpy教程"
date: "`r Sys.Date()`"
output: 
  html_document:
    toc: true
    toc_float: true
    code_folding: show
    theme: cosmo
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE, eval = FALSE)
```

# 🎯 教程目标

本教程将详细介绍如何使用`ICellbioRpy`包的`read_10x_mtx_to_h5ad()`函数，从多个10X Cell Ranger输出的MTX格式文件中读取数据，进行基本的质量控制，并整合为单一的H5AD文件，方便后续在Python环境中进行分析。

# 📋 前提条件

## 必需的软件环境

1. **R (≥ 4.0.0)**
2. **Python (≥ 3.7) + anndata包**
3. **必需的R包**: data.table, Matrix, ICellbioRpy

```{r check-requirements, eval=TRUE}
# 检查必需的R包
required_packages <- c("data.table", "Matrix", "reticulate")
missing_packages <- required_packages[!sapply(required_packages, requireNamespace, quietly = TRUE)]

if (length(missing_packages) > 0) {
  cat("需要安装以下R包:\n")
  cat("install.packages(c(", paste0("'", missing_packages, "'", collapse = ", "), "))\n")
} else {
  cat("✓ 所有必需的R包已安装\n")
}
```

## 10X数据格式说明

10X Cell Ranger输出的标准格式包含三个文件：

1. **matrix.mtx** (或 matrix.mtx.gz): 稀疏矩阵格式的基因表达数据
2. **features.tsv** (或 features.tsv.gz, genes.tsv): 基因信息，包含基因ID和基因名
3. **barcodes.tsv** (或 barcodes.tsv.gz): 细胞barcode列表

```
filtered_feature_bc_matrix/
├── matrix.mtx.gz
├── features.tsv.gz  (或 genes.tsv.gz)
└── barcodes.tsv.gz
```

# 🚀 开始教程

## 第1步: 环境设置

```{r setup-environment}
# 加载必需的包
library(ICellbioRpy)
library(data.table)
library(Matrix)

# 显示版本信息
cat("=== 包版本信息 ===\n")
cat("ICellbioRpy:", as.character(packageVersion("ICellbioRpy")), "\n")
cat("data.table:", as.character(packageVersion("data.table")), "\n")
cat("Matrix:", as.character(packageVersion("Matrix")), "\n")
```

## 第2步: 配置Python环境（必需步骤）

即使处理MTX格式数据，最终输出H5AD格式仍需要Python环境支持。

```{r configure-python}
# 配置Python环境
cat("配置Python环境...\n")

# 方法1: 使用默认Python环境（推荐）
configure_python_env(verbose = TRUE)

# 方法2: 指定conda环境（如果使用conda）
# configure_python_env(conda_env = "your_env_name", verbose = TRUE)

# 方法3: 指定Python路径
# configure_python_env(python_path = "/usr/local/bin/python3", verbose = TRUE)

# 验证anndata可用性
cat("\n验证anndata可用性...\n")
check_anndata_available()
```

**💡 配置要点:**

- 这一步骤至关重要，必须看到"✓ anndata is available"
- 如果配置失败，请确保Python环境中安装了anndata包
- 可以通过`pip install anndata`或`conda install -c conda-forge anndata`安装

## 第3步: 准备样本信息CSV文件

`read_10x_mtx_to_h5ad()`函数需要一个CSV文件来描述所有样本的文件路径。

### CSV文件格式要求

CSV文件必须包含以下4列：

- **Sample_id**: 样本标识符（将用于细胞ID重命名）
- **mtx_fns**: matrix.mtx文件的完整路径
- **features_fns**: features.tsv文件的完整路径
- **barcodes_fns**: barcodes.tsv文件的完整路径

### 示例：创建样本信息CSV

```{r create-sample-csv}
# 示例1: 创建样本信息表（请根据实际情况修改路径）
sample_info <- data.frame(
  Sample_id = c("sample1", "sample2", "sample3"),
  mtx_fns = c(
    "/path/to/sample1/filtered_feature_bc_matrix/matrix.mtx.gz",
    "/path/to/sample2/filtered_feature_bc_matrix/matrix.mtx.gz", 
    "/path/to/sample3/filtered_feature_bc_matrix/matrix.mtx.gz"
  ),
  features_fns = c(
    "/path/to/sample1/filtered_feature_bc_matrix/features.tsv.gz",
    "/path/to/sample2/filtered_feature_bc_matrix/features.tsv.gz",
    "/path/to/sample3/filtered_feature_bc_matrix/features.tsv.gz"
  ),
  barcodes_fns = c(
    "/path/to/sample1/filtered_feature_bc_matrix/barcodes.tsv.gz",
    "/path/to/sample2/filtered_feature_bc_matrix/barcodes.tsv.gz",
    "/path/to/sample3/filtered_feature_bc_matrix/barcodes.tsv.gz"
  ),
  stringsAsFactors = FALSE
)

# 保存为CSV文件
csv_file <- "samples_info.csv"
write.csv(sample_info, csv_file, row.names = FALSE)

cat("✓ 样本信息CSV文件已创建:", csv_file, "\n")
cat("包含", nrow(sample_info), "个样本\n")
```

### 示例：混合压缩格式

```{r mixed-format-example}
# 示例2: 混合压缩格式（有些压缩，有些不压缩）
sample_info_mixed <- data.frame(
  Sample_id = c("ctrl", "treat"),
  mtx_fns = c(
    "/path/to/ctrl/matrix.mtx.gz",     # 压缩格式
    "/path/to/treat/matrix.mtx"        # 非压缩格式
  ),
  features_fns = c(
    "/path/to/ctrl/features.tsv.gz",   # 压缩格式
    "/path/to/treat/genes.tsv"         # 非压缩，不同文件名
  ),
  barcodes_fns = c(
    "/path/to/ctrl/barcodes.tsv.gz",   # 压缩格式  
    "/path/to/treat/barcodes.tsv"      # 非压缩格式
  ),
  stringsAsFactors = FALSE
)

write.csv(sample_info_mixed, "samples_mixed.csv", row.names = FALSE)
```

## 第4步: 验证文件路径

在进行转换前，验证所有文件路径是否正确：

```{r verify-file-paths}
# 读取CSV文件进行验证
csv_file_to_check <- "samples_info.csv"  # 使用您的实际CSV文件

if (file.exists(csv_file_to_check)) {
  cat("✓ 找到CSV文件:", csv_file_to_check, "\n")
  
  # 读取文件内容
  sample_data <- read.csv(csv_file_to_check, stringsAsFactors = FALSE)
  cat("CSV文件包含", nrow(sample_data), "个样本\n")
  
  # 显示文件结构
  cat("\n=== CSV文件内容预览 ===\n")
  print(head(sample_data))
  
  # 检查文件是否存在（仅当路径是真实路径时）
  cat("\n=== 文件存在性检查 ===\n")
  for (i in 1:nrow(sample_data)) {
    sample_id <- sample_data$Sample_id[i]
    
    # 检查三个文件
    files_to_check <- c(
      mtx = sample_data$mtx_fns[i],
      features = sample_data$features_fns[i], 
      barcodes = sample_data$barcodes_fns[i]
    )
    
    cat("样本", sample_id, ":\n")
    for (file_type in names(files_to_check)) {
      file_path <- files_to_check[file_type]
      if (file.exists(file_path)) {
        file_size_mb <- round(file.size(file_path) / 1024^2, 2)
        cat("  ✓", file_type, "文件存在 (", file_size_mb, "MB)\n")
      } else {
        cat("  ✗", file_type, "文件不存在:", file_path, "\n")
      }
    }
  }
} else {
  cat("✗ 找不到CSV文件，请检查路径\n")
}
```

## 第5步: 执行数据读取和整合

现在执行主要的转换操作：

```{r read-and-integrate}
# 设置输出文件路径
output_h5ad <- "integrated_10x_data.h5ad"

cat("=== 开始读取和整合10X数据 ===\n")

# 执行转换
# 主要参数说明：
# - csv_file: 包含样本信息的CSV文件路径
# - output_h5ad: 输出的H5AD文件路径
# - min_counts_per_cell: QC过滤阈值，移除总计数低于此值的细胞
# - verbose: 显示详细进度信息
result <- read_10x_mtx_to_h5ad(
  csv_file = csv_file_to_check,
  output_h5ad = output_h5ad,
  min_counts_per_cell = 200,    # 默认QC阈值
  verbose = TRUE                # 显示详细信息
)

cat("✓ 数据整合完成！\n")
```

**🔍 处理流程说明:**

函数执行过程中会显示以下信息：

1. **读取CSV文件**: 验证文件格式和路径
2. **逐个处理样本**: 
   - 读取MTX矩阵（使用data.table高速读取）
   - 读取基因注释（features/genes文件）
   - 读取细胞barcode（barcodes文件）
   - 创建稀疏矩阵
3. **质量控制**: 移除总计数低于阈值的细胞
4. **细胞ID重命名**: 格式为 `{Sample_id}_{原始barcode}`
5. **数据整合**: 合并所有样本的矩阵
6. **输出H5AD**: 保存为AnnData格式

## 第6步: 验证转换结果

检查生成的H5AD文件：

```{r verify-results}
# 检查输出文件
if (file.exists(output_h5ad)) {
  cat("✓ H5AD文件创建成功!\n")
  cat("文件路径:", output_h5ad, "\n")
  
  # 显示文件大小
  file_size_mb <- round(file.size(output_h5ad) / 1024^2, 2)
  cat("文件大小:", file_size_mb, "MB\n")
  
  # 尝试读取验证
  tryCatch({
    # 导入anndata
    ad <- reticulate::import("anndata")
    
    # 读取H5AD文件
    adata <- ad$read_h5ad(output_h5ad)
    
    cat("\n=== 整合数据信息 ===\n")
    cat("总细胞数:", adata$shape[1], "\n")
    cat("总基因数:", adata$shape[2], "\n")
    
    # 检查细胞注释
    cat("\n=== 细胞注释信息 ===\n")
    obs_columns <- names(adata$obs)
    cat("注释列:", paste(obs_columns, collapse = ", "), "\n")
    
    # 显示样本分布
    if ("sample_id" %in% obs_columns) {
      sample_counts <- table(adata$obs$sample_id)
      cat("\n各样本细胞数量:\n")
      for (sample_name in names(sample_counts)) {
        cat("  ", sample_name, ":", sample_counts[[sample_name]], "个细胞\n")
      }
    }
    
    # 检查基因注释
    cat("\n=== 基因注释信息 ===\n")
    var_columns <- names(adata$var)
    cat("基因注释列:", paste(var_columns, collapse = ", "), "\n")
    
    # 显示数据稀疏性
    if (inherits(adata$X, "scipy.sparse.csr.csr_matrix")) {
      sparsity <- 1 - (adata$X$nnz / (adata$shape[1] * adata$shape[2]))
      cat("数据稀疏性:", round(sparsity * 100, 2), "%\n")
    }
    
  }, error = function(e) {
    cat("无法读取H5AD文件进行验证:", e$message, "\n")
    cat("但文件已成功创建\n")
  })
  
} else {
  cat("✗ H5AD文件创建失败\n")
}
```

## 第7步: 高级使用选项

### 调整质量控制参数

```{r advanced-qc}
# 更严格的QC过滤
read_10x_mtx_to_h5ad(
  csv_file = csv_file_to_check,
  output_h5ad = "integrated_strict_qc.h5ad",
  min_counts_per_cell = 500,    # 更高的阈值
  verbose = TRUE
)

# 更宽松的QC过滤
read_10x_mtx_to_h5ad(
  csv_file = csv_file_to_check,
  output_h5ad = "integrated_loose_qc.h5ad", 
  min_counts_per_cell = 100,    # 更低的阈值
  verbose = TRUE
)
```

### 处理大数据集的建议

```{r large-dataset-tips}
# 对于大数据集（>100万细胞），建议：

# 1. 监控内存使用
cat("当前内存使用:\n")
gc()

# 2. 分批处理（如果样本很多）
# 可以将样本分成多个批次，分别处理后再合并

# 3. 使用更严格的QC减少数据量
# min_counts_per_cell = 1000  # 更严格的过滤

# 4. 检查磁盘空间
# 确保有足够空间保存输出文件
```

# 🐍 在Python中使用整合数据

转换完成后，您可以在Python环境中加载和分析数据：

```{python python-analysis, eval=FALSE}
import scanpy as sc
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# 配置scanpy
sc.settings.verbosity = 3
sc.settings.set_figure_params(dpi=80, facecolor='white')

# 读取整合后的数据
adata = sc.read_h5ad('integrated_10x_data.h5ad')

print(f"数据维度: {adata.shape}")
print(f"样本信息: {adata.obs['sample_id'].value_counts()}")

# 基本质量控制可视化
# 计算额外的QC指标
adata.var['mt'] = adata.var_names.str.startswith('MT-')
sc.pp.calculate_qc_metrics(adata, percent_top=None, log1p=False, inplace=True)

# 可视化QC指标
fig, axes = plt.subplots(1, 3, figsize=(15, 5))

# UMI分布
sns.histplot(adata.obs['total_counts'], bins=50, ax=axes[0])
axes[0].set_xlabel('Total UMI counts')
axes[0].set_ylabel('Number of cells')

# 基因数分布  
sns.histplot(adata.obs['n_genes_by_counts'], bins=50, ax=axes[1])
axes[1].set_xlabel('Number of genes')
axes[1].set_ylabel('Number of cells')

# 样本分布
adata.obs['sample_id'].value_counts().plot(kind='bar', ax=axes[2])
axes[2].set_xlabel('Sample')
axes[2].set_ylabel('Number of cells')
axes[2].tick_params(axis='x', rotation=45)

plt.tight_layout()
plt.show()

# 进一步的质量控制
# 过滤低质量细胞和基因
sc.pp.filter_cells(adata, min_genes=200)  # 过滤表达基因数<200的细胞
sc.pp.filter_genes(adata, min_cells=3)    # 过滤在<3个细胞中表达的基因

# 标准化和对数转换
adata.raw = adata  # 保存原始数据
sc.pp.normalize_total(adata, target_sum=1e4)  # 标准化到每个细胞10,000个分子
sc.pp.log1p(adata)  # 对数转换

# 寻找高变基因
sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5)
sc.pl.highly_variable_genes(adata)

# 只保留高变基因
adata.raw = adata  # 再次保存
adata = adata[:, adata.var.highly_variable]

# PCA分析
sc.pp.scale(adata, max_value=10)  # 缩放数据
sc.tl.pca(adata, svd_solver='arpack')
sc.pl.pca_variance_ratio(adata, log=True, n_top_genes=50)

# 计算邻居图和UMAP
sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40)
sc.tl.umap(adata)

# 聚类分析
sc.tl.leiden(adata, resolution=0.5)

# 可视化结果
sc.pl.umap(adata, color=['sample_id', 'leiden'], legend_loc='on data')

# 寻找标记基因
sc.tl.rank_genes_groups(adata, 'leiden', method='wilcoxon')
sc.pl.rank_genes_groups(adata, n_genes=5, sharey=False)
```

# 🔧 常见问题排查

## 问题1: CSV文件格式错误

**错误信息**: "Missing required columns" 或 "Invalid CSV format"

```{r csv-troubleshooting}
# 检查CSV文件格式
csv_file_check <- "samples_info.csv"

if (file.exists(csv_file_check)) {
  # 读取CSV文件
  csv_data <- read.csv(csv_file_check, stringsAsFactors = FALSE)
  
  # 检查必需列
  required_cols <- c("Sample_id", "mtx_fns", "features_fns", "barcodes_fns")
  missing_cols <- setdiff(required_cols, colnames(csv_data))
  
  if (length(missing_cols) > 0) {
    cat("✗ 缺少必需列:", paste(missing_cols, collapse = ", "), "\n")
    cat("当前列名:", paste(colnames(csv_data), collapse = ", "), "\n")
  } else {
    cat("✓ CSV文件格式正确\n")
  }
  
  # 检查数据类型
  cat("各列数据类型:\n")
  str(csv_data)
  
} else {
  cat("✗ CSV文件不存在\n")
}
```

## 问题2: MTX文件读取失败

**错误信息**: "Error reading MTX file" 或 "Invalid matrix format"

```{r mtx-troubleshooting}
# 手动检查MTX文件格式
test_mtx_file <- "path/to/your/matrix.mtx.gz"  # 替换为实际路径

if (file.exists(test_mtx_file)) {
  # 读取前几行检查格式
  if (grepl("\\.gz$", test_mtx_file)) {
    # 压缩文件
    conn <- gzfile(test_mtx_file, "r")
  } else {
    # 非压缩文件
    conn <- file(test_mtx_file, "r")
  }
  
  header_lines <- readLines(conn, n = 10)
  close(conn)
  
  cat("MTX文件前10行:\n")
  for (i in seq_along(header_lines)) {
    cat(sprintf("%2d: %s\n", i, header_lines[i]))
  }
  
  # 检查格式
  if (grepl("^%%MatrixMarket", header_lines[1])) {
    cat("✓ MTX文件格式正确\n")
  } else {
    cat("✗ MTX文件格式可能有问题\n")
  }
} else {
  cat("✗ MTX文件不存在\n")
}
```

## 问题3: 内存不足

**错误信息**: "Cannot allocate memory" 或系统变慢

```{r memory-troubleshooting}
# 内存管理策略
cat("=== 内存使用诊断 ===\n")

# 检查当前内存使用
gc_info <- gc()
cat("当前内存使用:\n")
print(gc_info)

# 获取系统内存信息（Linux/Mac）
tryCatch({
  if (Sys.info()["sysname"] == "Linux") {
    mem_info <- system("free -h", intern = TRUE)
    cat("系统内存信息:\n")
    cat(paste(mem_info, collapse = "\n"), "\n")
  }
}, error = function(e) {
  cat("无法获取系统内存信息\n")
})

# 内存优化建议
cat("\n=== 内存优化建议 ===\n")
cat("1. 提高QC阈值减少细胞数: min_counts_per_cell = 500\n")
cat("2. 分批处理大数据集\n")
cat("3. 使用更多RAM或云计算平台\n")
cat("4. 清理环境: rm(unused_objects); gc()\n")
```

## 问题4: Python环境问题

**错误信息**: "anndata not available" 或 Python相关错误

```{r python-troubleshooting}
# Python环境诊断
cat("=== Python环境诊断 ===\n")

# 检查reticulate配置
py_config <- reticulate::py_config()
cat("Python路径:", py_config$python, "\n")
cat("Python版本:", py_config$version, "\n")

# 检查可用的conda环境
tryCatch({
  conda_envs <- reticulate::conda_list()
  if (nrow(conda_envs) > 0) {
    cat("可用的conda环境:\n")
    print(conda_envs[, c("name", "python")])
  }
}, error = function(e) {
  cat("无法列出conda环境\n")
})

# 测试anndata导入
tryCatch({
  ad <- reticulate::import("anndata")
  cat("✓ anndata导入成功，版本:", ad$`__version__`, "\n")
}, error = function(e) {
  cat("✗ anndata导入失败:", e$message, "\n")
  cat("解决方法: pip install anndata\n")
})
```

## 问题5: 基因名不一致

**错误信息**: "Gene names differ between samples"

```{r gene-consistency}
# 检查多个样本的基因一致性
check_gene_consistency <- function(csv_file) {
  if (!file.exists(csv_file)) {
    cat("CSV文件不存在\n")
    return()
  }
  
  sample_data <- read.csv(csv_file, stringsAsFactors = FALSE)
  
  cat("检查基因名一致性...\n")
  
  all_genes <- list()
  
  for (i in 1:min(nrow(sample_data), 3)) {  # 只检查前3个样本
    features_file <- sample_data$features_fns[i]
    
    if (file.exists(features_file)) {
      # 读取features文件
      features <- data.table::fread(features_file, header = FALSE)
      genes <- features[[2]]  # 第二列通常是基因名
      
      all_genes[[sample_data$Sample_id[i]]] <- genes
      cat("样本", sample_data$Sample_id[i], ":", length(genes), "个基因\n")
    }
  }
  
  # 检查基因一致性
  if (length(all_genes) > 1) {
    first_genes <- all_genes[[1]]
    consistent <- TRUE
    
    for (i in 2:length(all_genes)) {
      if (!identical(first_genes, all_genes[[i]])) {
        consistent <- FALSE
        break
      }
    }
    
    if (consistent) {
      cat("✓ 所有样本基因名一致\n")
    } else {
      cat("⚠ 样本间基因名不一致，将使用基因交集\n")
      
      # 计算交集
      common_genes <- Reduce(intersect, all_genes)
      cat("共同基因数:", length(common_genes), "\n")
    }
  }
}

# 运行检查
check_gene_consistency("samples_info.csv")
```

# 📊 性能基准测试

```{r performance-benchmark}
# 简单的性能测试
benchmark_reading <- function() {
  cat("=== 性能基准测试 ===\n")
  
  # 记录开始时间
  start_time <- Sys.time()
  
  # 模拟小规模测试（如果有测试数据）
  cat("开始时间:", format(start_time), "\n")
  
  # 这里可以运行实际的转换测试
  # result <- read_10x_mtx_to_h5ad(...)
  
  # 记录结束时间
  end_time <- Sys.time()
  elapsed <- difftime(end_time, start_time, units = "mins")
  
  cat("结束时间:", format(end_time), "\n")
  cat("总耗时:", round(elapsed, 2), "分钟\n")
  
  # 内存使用统计
  gc_final <- gc()
  cat("最终内存使用:\n")
  print(gc_final)
}

# 如果有测试数据，可以运行基准测试
# benchmark_reading()
```

# 💡 最佳实践和建议

## 数据准备建议

1. **文件组织**: 保持一致的目录结构
2. **路径管理**: 使用绝对路径避免路径问题  
3. **备份数据**: 处理前备份原始数据
4. **版本记录**: 记录使用的软件版本

## 质量控制建议

```{r qc-recommendations}
cat("=== 质量控制参数建议 ===\n")
cat("细胞类型           | min_counts_per_cell 建议值\n")
cat("高质量PBMC        | 200-500\n")  
cat("组织样本          | 500-1000\n")
cat("单细胞核RNA-seq   | 100-300\n")
cat("10X v3化学试剂    | 500-1000\n")
cat("10X v2化学试剂    | 200-500\n")
```

## 计算资源建议

```{r resource-recommendations}
cat("=== 计算资源建议 ===\n")
cat("数据规模          | 内存需求    | 建议配置\n")
cat("< 10,000细胞     | 4-8 GB     | 普通PC\n")
cat("10,000-50,000细胞| 8-16 GB    | 工作站\n") 
cat("50,000-100,000细胞| 16-32 GB   | 高配工作站\n")
cat("> 100,000细胞    | 32+ GB     | 服务器/云计算\n")
```

# 📚 下一步分析

整合完成后，建议的分析流程：

## 在Python中的分析

1. **质量控制**: 更精细的QC和过滤
2. **标准化**: 数据标准化和对数转换
3. **特征选择**: 寻找高变基因
4. **降维**: PCA和UMAP分析
5. **聚类**: leiden或louvain聚类
6. **注释**: 细胞类型注释
7. **差异分析**: 标记基因识别

## 推荐工具链

- **scanpy**: 核心分析流程
- **scvelo**: RNA velocity分析
- **cellrank**: 细胞命运预测
- **scanorama**: 批次效应校正
- **squidpy**: 空间转录组（如果适用）

# 🔗 相关资源

## 官方文档

- [10X Genomics文档](https://support.10xgenomics.com/)
- [scanpy教程](https://scanpy-tutorials.readthedocs.io/)
- [AnnData文档](https://anndata.readthedocs.io/)

## 相关教程

- 教程1: 1CellBio转H5AD
- 教程2: 1CellBio转Seurat
- 教程3: Seurat转H5AD

---

**需要帮助？**

- 查看函数文档: `?read_10x_mtx_to_h5ad`
- GitHub Issues: [项目地址]
- 联系维护者: [邮箱地址]

**小贴士**: 第一次使用建议先用小数据集测试，确认流程无误后再处理大数据集。